{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq07UWRfCUJi"
      },
      "source": [
        "# Fine Tuning guide with OpenAI\n",
        "\n",
        "Questo notebook Python è stato sviluppato per effettuare il fine tuning un modello di OpenAI tramite un dataset preparato precedentemente.\n",
        "\n",
        "Il processo consiste nel:\n",
        "1) Crea tre differenti file: training, validazione e test\n",
        "2) Caricare sulla piattaforma i file training e validazione\n",
        "3) Creazione fine tuning job\n",
        "4) Verifica lo stato del job\n",
        "5) Valutazione risultati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyCLWIpFCLgw",
        "outputId": "23becbec-d00c-41b5-a599-61afcc719567"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Installazione dei pacchetti necessari per l'esecuzione del notebook\n",
        "\n",
        "!pip install --quiet openai python-dotenv scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O0KdPxY_CTSK"
      },
      "outputs": [],
      "source": [
        "import dotenv, os\n",
        "dotenv.load_dotenv(override=True)\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzndWqV_ofst"
      },
      "source": [
        "# Training, validation & test file creation\n",
        "\n",
        "## Input\n",
        "- **File di Input:**  \n",
        "  Un file `dataset.jsonl` contenente dati in formato JSONL, in cui ogni riga rappresenta un esempio.\n",
        "- **Struttura dei Dati:**  \n",
        "  Ogni esempio deve essere un oggetto JSON che include una chiave `messages`.  \n",
        "  - `messages` è una lista di messaggi, e ogni messaggio deve avere:  \n",
        "    - **role:** con valore `system`, `user` o `assistant`.\n",
        "    - **content:** il testo associato al messaggio.\n",
        "\n",
        "## Output\n",
        "- **training.jsonl:**  \n",
        "  Contiene il 70% degli esempi del dataset originale.\n",
        "- **validation.jsonl:**  \n",
        "  Contiene il 15% degli esempi.\n",
        "- **test.jsonl:**  \n",
        "  Contiene il restante 15% degli esempi.\n",
        "- **test.csv:**  \n",
        "  File CSV derivato dal test set, in cui ogni riga ha colonne separate per:\n",
        "  - `system`\n",
        "  - `user`\n",
        "  - `assistant`\n",
        "\n",
        "## Parametri Interni Regolabili\n",
        "- **Percentuali di Partizione:**  \n",
        "  - `train_ratio = 0.70` (70% per training)\n",
        "  - `val_ratio = 0.15` (15% per validazione)\n",
        "  - `test_ratio = 0.15` (15% per test; il test set viene calcolato come il resto degli esempi)\n",
        "- **Percorsi dei File:**  \n",
        "  Modifica i nomi dei file per:\n",
        "  - `dataset_file` (file di input)\n",
        "  - `train_file` (output training)\n",
        "  - `val_file` (output validation)\n",
        "  - `test_file` (output test in formato JSONL)\n",
        "  - `test_csv_file` (output test in formato CSV)\n",
        "\n",
        "  ## Note\n",
        "  Il file in formato csv può essere utilizzato nel tool `Evaluation` nella platform di OpenAI https://platform.openai.com/evaluations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KzJFu_sj630",
        "outputId": "f6d984df-de95-4715-c79d-83cea5dc6823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Creazione completata\n",
            "\t📄training.jsonl (32 esempi)\n",
            "\t📄validation.jsonl (6 esempi)\n",
            "\t📄test.jsonl e test.csv (8 esempi).\n"
          ]
        }
      ],
      "source": [
        "import json, csv\n",
        "import random\n",
        "\n",
        "# Configura i percorsi dei file\n",
        "dataset_file = \"dataset.jsonl\"\n",
        "train_file = \"training.jsonl\"\n",
        "val_file = \"validation.jsonl\"\n",
        "test_file = \"test.jsonl\"\n",
        "test_csv_file = \"test.csv\"\n",
        "\n",
        "train_ratio = 0.70  # 70% training\n",
        "val_ratio = 0.15    # 15% validation\n",
        "test_ratio = 0.15   # 15% test\n",
        "\n",
        "with open(dataset_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = [json.loads(line) for line in f]\n",
        "\n",
        "# Mescola casualmente i dati\n",
        "random.shuffle(data)\n",
        "\n",
        "# Calcola gli indici per la divisione\n",
        "n = len(data)\n",
        "train_size = int(n * train_ratio)\n",
        "val_size = int(n * val_ratio)\n",
        "# Il test prende tutto il resto, per garantire che la somma sia 100%\n",
        "test_size = n - train_size - val_size\n",
        "\n",
        "# Suddividi il dataset\n",
        "train_data = data[:train_size]\n",
        "val_data = data[train_size:train_size+val_size]\n",
        "test_data = data[train_size+val_size:]\n",
        "\n",
        "with open(train_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for entry in train_data:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "with open(val_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for entry in val_data:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "with open(test_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for entry in test_data:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "def extract_messages(message_list):\n",
        "  \"\"\"\n",
        "  Estrae i messaggi di ruolo e contenuto da una lista di messaggi\n",
        "  \"\"\"\n",
        "  roles = {\"system\": \"\", \"user\": \"\", \"assistant\": \"\"}\n",
        "  for message in message_list:\n",
        "      role = message.get(\"role\")\n",
        "      if role in roles:\n",
        "          roles[role] = message.get(\"content\", \"\")\n",
        "  return roles\n",
        "\n",
        "with open(test_csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    fieldnames = [\"system\", \"user\", \"assistant\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for entry in test_data:\n",
        "        roles = extract_messages(entry.get(\"messages\", []))\n",
        "        writer.writerow(roles)\n",
        "\n",
        "print(f\"✅ Creazione completata\")\n",
        "print(f\"\\t📄{train_file} ({len(train_data)} esempi)\")\n",
        "print(f\"\\t📄{val_file} ({len(val_data)} esempi)\")\n",
        "print(f\"\\t📄{test_file} e {test_csv_file} ({len(test_data)} esempi).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blraa8oDhZWe"
      },
      "source": [
        "# Upload training and validation files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZA9Ze6VCk4F",
        "outputId": "0e51ba24-a1dd-4f28-e2e9-ebb2f604cfdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file ID: file-BW8HoFupjBLj4f2NNQ4DSs\n",
            "Validation file ID: file-TEB8YqBTryZgHKRxUnVngn\n"
          ]
        }
      ],
      "source": [
        "# Upload a training file\n",
        "\n",
        "def upload_file(file_name: str, purpose: str) -> str:\n",
        "    with open(file_name, \"rb\") as file_fd:\n",
        "        response = client.files.create(file=file_fd, purpose=purpose)\n",
        "    return response.id\n",
        "\n",
        "training_file_id = upload_file(train_file, \"fine-tune\")\n",
        "validation_file_id = upload_file(val_file, \"fine-tune\")\n",
        "\n",
        "print(\"Training file ID:\", training_file_id)\n",
        "print(\"Validation file ID:\", validation_file_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGlllX9WiKt6"
      },
      "source": [
        "# Create FT job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeXgP_2ViBCa",
        "outputId": "c04a5f27-7dea-4224-a9eb-2a0247936074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FineTuningJob(id='ftjob-5UYBh40uYtHVzr5iTLY0Uo3g', created_at=1739808524, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-eF6QgROkc7s5rEEip6fS8fjY', result_files=[], seed=994339359, status='validating_files', trained_tokens=None, training_file='file-BW8HoFupjBLj4f2NNQ4DSs', validation_file='file-TEB8YqBTryZgHKRxUnVngn', estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto')), type='supervised'), user_provided_suffix=None)\n"
          ]
        }
      ],
      "source": [
        "MODEL = \"gpt-4o-mini-2024-07-18\"\n",
        "\n",
        "job = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    validation_file=validation_file_id,\n",
        "    model=MODEL,\n",
        "    # method={\n",
        "    #   \"type\": \"supervised\",\n",
        "    #   \"supervised\": {\n",
        "    #     \"hyperparameters\": {\n",
        "    #       \"n_epochs\": 2,\n",
        "    #       \"batch_size\": 10,\n",
        "    #       \"learning_rate_multiplier\": 1.0\n",
        "    #     }\n",
        "    #   }\n",
        "    # }\n",
        ")\n",
        "\n",
        "# print(job)\n",
        "print(\"Job ID:\", job.id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8FKilv-hUxq"
      },
      "source": [
        "# Check job status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eBBomzqFMuT",
        "outputId": "7415a887-21dd-4576-cfb2-cf473181b99f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List 10 fine-tuning jobs\n",
            "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-5UYBh40uYtHVzr5iTLY0Uo3g', created_at=1739808524, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:rsn-labcamp::B1y5EZ1L', finished_at=1739808987, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-eF6QgROkc7s5rEEip6fS8fjY', result_files=['file-3CcGBNactwKvBo3xSVuGM4'], seed=994339359, status='succeeded', trained_tokens=13914, training_file='file-BW8HoFupjBLj4f2NNQ4DSs', validation_file='file-TEB8YqBTryZgHKRxUnVngn', estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=3)), type='supervised'), user_provided_suffix=None), FineTuningJob(id='ftjob-bFNIrGhRuYsjwELebRog3oOk', created_at=1739655494, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:rsn-labcamp::B1KPFoIm', finished_at=1739656467, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-eF6QgROkc7s5rEEip6fS8fjY', result_files=['file-XR1psnGbxGoahNgDpxefpM'], seed=2046445513, status='succeeded', trained_tokens=38799, training_file='file-CNmAwT4Zr857QqiU43vdSD', validation_file='file-D6j5LiuDzAiiqHzsvvA3Cg', estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=3)), type='supervised'), user_provided_suffix=None)], has_more=False, object='list')\n",
            "==================================================\n",
            "Retrieve the state of a fine-tune\n",
            "Job ID: ftjob-5UYBh40uYtHVzr5iTLY0Uo3g\n",
            "Status: succeeded\n",
            "Fine-tuned model ID: ft:gpt-4o-mini-2024-07-18:rsn-labcamp::B1y5EZ1L\n"
          ]
        }
      ],
      "source": [
        "# Work with fine-tuning jobs\n",
        "\n",
        "print(\"List 10 fine-tuning jobs\")\n",
        "print(client.fine_tuning.jobs.list(limit=10))\n",
        "\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"Retrieve the state of a fine-tune\")\n",
        "response = client.fine_tuning.jobs.retrieve(job.id)\n",
        "\n",
        "print(\"Job ID:\", response.id)\n",
        "print(\"Status:\", response.status)\n",
        "fine_tuned_model_id = response.fine_tuned_model\n",
        "\n",
        "if fine_tuned_model_id is None:\n",
        "    print(\"Fine-tuned model ID not found. Your job has likely not been completed yet.\")\n",
        "else:\n",
        "    print(\"Fine-tuned model ID:\", fine_tuned_model_id)\n",
        "\n",
        "# Cancel a job\n",
        "#client.fine_tuning.jobs.cancel(fine_tuned_model_id)\n",
        "\n",
        "# List up to 10 events from a fine-tuning job\n",
        "#client.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tuned_model_id, limit=10)\n",
        "\n",
        "# Delete a fine-tuned model\n",
        "#client.models.delete(fine_tuned_model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNckwWMZYzS7"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Tramite la cosine similarity tra gli embeddings della risposta desiderata vs quella ottenuta, si calcola la distanza tra le risposte così da valutare il fine tuning: più è alto il risultato, maggiore è somiglianza/vicinanza.\n",
        "\n",
        "Tramite le variabili di seguito è possibile regolare:\n",
        "\n",
        "- `N_EXAMPLES`: numero di esempi del test dataset da valutare\n",
        "- `embeddings_model`: modello di OpenAI per il calcolo degli embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKfi69C7dmPy",
        "outputId": "5ad36da6-ad97-47dd-e1a7-d945910c2ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esempio 1 - Similarità: 0.8978\n",
            "Input: Quali sono le date del Festival di Sanremo 2024?\n",
            "Risposta di riferimento: Il settantaquattresimo Festival di Sanremo si è svolto dal 6 al 10 febbraio 2024.\n",
            "Risposta del modello: Il Festival di Sanremo 2024 si è svolto dal 6 al 10 febbraio 2024.\n",
            "--------------------------------------------------\n",
            "Esempio 2 - Similarità: 0.9080\n",
            "Input: Quale artista ha vinto il Festival di Sanremo 2024?\n",
            "Risposta di riferimento: Angelina Mango è stata la vincitrice del Festival di Sanremo 2024 con il brano 'La noia'.\n",
            "Risposta del modello: Il Festival di Sanremo 2024 è stato vinto da Angelina Mango con il brano 'La noia'.\n",
            "--------------------------------------------------\n",
            "Esempio 3 - Similarità: 1.0000\n",
            "Input: Quanti artisti hanno partecipato al Festival di Sanremo 2024?\n",
            "Risposta di riferimento: Al Festival di Sanremo 2024 hanno partecipato 30 artisti.\n",
            "Risposta del modello: Al Festival di Sanremo 2024 hanno partecipato 30 artisti.\n",
            "--------------------------------------------------\n",
            "Esempio 4 - Similarità: 0.6506\n",
            "Input: Qual è stata la canzone vincitrice del Festival di Sanremo 2024?\n",
            "Risposta di riferimento: La canzone vincitrice del Festival di Sanremo 2024 è 'La noia' di Angelina Mango.\n",
            "Risposta del modello: La canzone vincitrice del Festival di Sanremo 2024 è stata 'A me mi piace' di Annalisa.\n",
            "--------------------------------------------------\n",
            "Esempio 5 - Similarità: 0.7198\n",
            "Input: Chi sono stati i giudici del Festival di Sanremo 2024?\n",
            "Risposta di riferimento: I giudici del Festival di Sanremo 2024 includevano una giuria di esperti della stampa, una giuria della radio e il pubblico a casa tramite televoto, ciascuna con un peso specifico nelle votazioni.\n",
            "Risposta del modello: I giudici del Festival di Sanremo 2024 sono stati: Fabio Fazio, Geppi Cucciari, Teresa Mannino, Lorella Cuccarini e Giuseppe Fiorello.\n",
            "--------------------------------------------------\n",
            "Esempio 6 - Similarità: 1.0000\n",
            "Input: Quanti artisti hanno partecipato al Festival di Sanremo 2024?\n",
            "Risposta di riferimento: Al Festival di Sanremo 2024 hanno partecipato un totale di 30 artisti.\n",
            "Risposta del modello: Al Festival di Sanremo 2024 hanno partecipato un totale di 30 artisti.\n",
            "--------------------------------------------------\n",
            "Esempio 7 - Similarità: 0.8978\n",
            "Input: Quali premi sono stati assegnati durante il Festival di Sanremo 2024?\n",
            "Risposta di riferimento: Durante il Festival di Sanremo 2024 sono stati assegnati vari premi, tra cui il Premio della Critica a Loredana Bertè e il Premio 'Sergio Bardotti' a Fiorella Mannoia.\n",
            "Risposta del modello: Durante il Festival di Sanremo 2024 sono stati assegnati diversi premi tra cui il Premio della Critica 'Mia Martini' a Loredana Bertè, il Premio 'Sergio Bardotti' per il miglior testo a Fiorella Mannoia e il Premio 'Giancarlo Bigazzi' per la miglior composizione musicale a Giorgia.\n",
            "--------------------------------------------------\n",
            "Esempio 8 - Similarità: 0.7309\n",
            "Input: Quanti artisti emergenti hanno partecipato al Festival di Sanremo 2024?\n",
            "Risposta di riferimento: Tra i 30 artisti partecipanti al Festival di Sanremo 2024, 3 provengono dal concorso Sanremo Giovani 2023.\n",
            "Risposta del modello: Al Festival di Sanremo 2024, hanno partecipato 16 artisti emergenti.\n",
            "--------------------------------------------------\n",
            "Esempio 9 - Similarità: 0.7911\n",
            "Input: Quando è iniziato il PrimaFestival nel 2024?\n",
            "Risposta di riferimento: Il PrimaFestival 2024 è iniziato il 3 febbraio e si è concluso il 10 febbraio, trasmettendo anticipazioni e commenti sull'evento.\n",
            "Risposta del modello: Il PrimaFestival 2024 è iniziato il 2 maggio 2024.\n",
            "--------------------------------------------------\n",
            "Esempio 10 - Similarità: 0.8823\n",
            "Input: Qual è stato il risultato di Angelina Mango all'Eurovision Song Contest 2024?\n",
            "Risposta di riferimento: Angelina Mango, vincitrice del Festival di Sanremo 2024 con 'La noia', ha rappresentato l'Italia all'Eurovision Song Contest 2024, terminando al settimo posto.\n",
            "Risposta del modello: Angelina Mango ha partecipato all'Eurovision Song Contest 2024 rappresentando l'Italia con il brano 'La noia'. Il suo risultato finale è stato il sesto posto, ottenendo un totale di 162 punti.\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "\n",
            "Similarità media: 0.8478\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Legge i primi N esempi dal file test.jsonl\n",
        "\n",
        "N_EXAMPLES=10\n",
        "embeddings_model=\"text-embedding-3-small\"\n",
        "\n",
        "examples = []\n",
        "with open(test_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= N_EXAMPLES:\n",
        "            break\n",
        "        examples.append(json.loads(line))\n",
        "\n",
        "def get_embedding(text, model=embeddings_model):\n",
        "    response = client.embeddings.create(input=text, model=model)\n",
        "    return response.data[0].embedding\n",
        "\n",
        "def cosine_sim(vec1, vec2):\n",
        "    return cosine_similarity([vec1], [vec2])[0][0]\n",
        "\n",
        "def get_model_response(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=fine_tuned_model_id,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "total_similarity = 0\n",
        "valid_examples = 0\n",
        "\n",
        "for i, example in enumerate(examples):\n",
        "    messages = example[\"messages\"]\n",
        "    user_message = next((msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\"), None)\n",
        "    reference_response = next((msg[\"content\"] for msg in messages if msg[\"role\"] == \"assistant\"), None)\n",
        "\n",
        "    if user_message is None or reference_response is None:\n",
        "        print(f\"Esempio {i} non valido: manca un messaggio user o assistant\")\n",
        "        continue\n",
        "\n",
        "    model_response = get_model_response(user_message)\n",
        "\n",
        "    ref_embedding = get_embedding(reference_response)\n",
        "    model_embedding = get_embedding(model_response)\n",
        "\n",
        "    similarity = cosine_sim(ref_embedding, model_embedding)\n",
        "\n",
        "    total_similarity += similarity\n",
        "    valid_examples += 1\n",
        "\n",
        "    print(f\"Esempio {i+1} - Similarità: {similarity:.4f}\")\n",
        "    print(\"Input:\", user_message)\n",
        "    print(\"Risposta di riferimento:\", reference_response)\n",
        "    print(\"Risposta del modello:\", model_response)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"-\" * 50 + \"\\n\")\n",
        "if valid_examples > 0:\n",
        "    average_similarity = total_similarity / valid_examples\n",
        "    print(f\"Similarità media: {average_similarity:.4f}\")\n",
        "else:\n",
        "    print(\"❌ Nessun esempio valido per il calcolo della similarità media.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
